{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "**Chapter 6 â€“ Decision Trees**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "_This notebook contains all the sample code and solutions to the exercises in chapter 6._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "First, let\u0027s make sure this notebook works well in both python 2 and 3, import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [],
      "source": [
        "# To support both python 2 and python 3\n",
        "from __future__ import division, print_function, unicode_literals\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook\u0027s output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc(\u0027axes\u0027, labelsize\u003d14)\n",
        "mpl.rc(\u0027xtick\u0027, labelsize\u003d12)\n",
        "mpl.rc(\u0027ytick\u0027, labelsize\u003d12)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR \u003d \".\"\n",
        "CHAPTER_ID \u003d \"decision_trees\"\n",
        "\n",
        "def image_path(fig_id):\n",
        "    return os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id)\n",
        "\n",
        "def save_fig(fig_id, tight_layout\u003dTrue):\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(image_path(fig_id) + \".png\", format\u003d\u0027png\u0027, dpi\u003d300)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "# Training and visualizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": "DecisionTreeClassifier(class_weight\u003dNone, criterion\u003d\u0027gini\u0027, max_depth\u003d2,\n            max_features\u003dNone, max_leaf_nodes\u003dNone,\n            min_impurity_decrease\u003d0.0, min_impurity_split\u003dNone,\n            min_samples_leaf\u003d1, min_samples_split\u003d2,\n            min_weight_fraction_leaf\u003d0.0, presort\u003dFalse, random_state\u003d42,\n            splitter\u003d\u0027best\u0027)"
          },
          "metadata": {},
          "output_type": "execute_result",
          "execution_count": 33
        }
      ],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "iris \u003d load_iris()\n",
        "X \u003d iris.data[:, 2:] # petal length and width\n",
        "y \u003d iris.target\n",
        "\n",
        "tree_clf \u003d DecisionTreeClassifier(max_depth\u003d2, random_state\u003d42)\n",
        "tree_clf.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import export_graphviz\n",
        "\n",
        "export_graphviz(\n",
        "        tree_clf,\n",
        "        out_file\u003dimage_path(\"iris_tree.dot\"),\n",
        "        feature_names\u003diris.feature_names[2:],\n",
        "        class_names\u003diris.target_names,\n",
        "        rounded\u003dTrue,\n",
        "        filled\u003dTrue\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m\u003cipython-input-6-bff0ddd22c36\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m\u003d\u001b[0m\u001b[1;34m\"lower right\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[1;33m\u003d\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---\u003e 28\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m\u003d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[0mplot_decision_boundary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree_clf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2.45\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2.45\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"k-\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[1;33m\u003d\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name \u0027plt\u0027 is not defined"
          ],
          "ename": "NameError",
          "evalue": "name \u0027plt\u0027 is not defined",
          "output_type": "error"
        }
      ],
      "source": [
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "def plot_decision_boundary(clf, X, y, axes\u003d[0, 7.5, 0, 3], iris\u003dTrue, legend\u003dFalse, plot_training\u003dTrue):\n",
        "    x1s \u003d np.linspace(axes[0], axes[1], 100)\n",
        "    x2s \u003d np.linspace(axes[2], axes[3], 100)\n",
        "    x1, x2 \u003d np.meshgrid(x1s, x2s)\n",
        "    X_new \u003d np.c_[x1.ravel(), x2.ravel()]\n",
        "    y_pred \u003d clf.predict(X_new).reshape(x1.shape)\n",
        "    custom_cmap \u003d ListedColormap([\u0027#fafab0\u0027,\u0027#9898ff\u0027,\u0027#a0faa0\u0027])\n",
        "    plt.contourf(x1, x2, y_pred, alpha\u003d0.3, cmap\u003dcustom_cmap)\n",
        "    if not iris:\n",
        "        custom_cmap2 \u003d ListedColormap([\u0027#7d7d58\u0027,\u0027#4c4c7f\u0027,\u0027#507d50\u0027])\n",
        "        plt.contour(x1, x2, y_pred, cmap\u003dcustom_cmap2, alpha\u003d0.8)\n",
        "    if plot_training:\n",
        "        plt.plot(X[:, 0][y\u003d\u003d0], X[:, 1][y\u003d\u003d0], \"yo\", label\u003d\"Iris-Setosa\")\n",
        "        plt.plot(X[:, 0][y\u003d\u003d1], X[:, 1][y\u003d\u003d1], \"bs\", label\u003d\"Iris-Versicolor\")\n",
        "        plt.plot(X[:, 0][y\u003d\u003d2], X[:, 1][y\u003d\u003d2], \"g^\", label\u003d\"Iris-Virginica\")\n",
        "        plt.axis(axes)\n",
        "    if iris:\n",
        "        plt.xlabel(\"Petal length\", fontsize\u003d14)\n",
        "        plt.ylabel(\"Petal width\", fontsize\u003d14)\n",
        "    else:\n",
        "        plt.xlabel(r\"$x_1$\", fontsize\u003d18)\n",
        "        plt.ylabel(r\"$x_2$\", fontsize\u003d18, rotation\u003d0)\n",
        "    if legend:\n",
        "        plt.legend(loc\u003d\"lower right\", fontsize\u003d14)\n",
        "\n",
        "plt.figure(figsize\u003d(8, 4))\n",
        "plot_decision_boundary(tree_clf, X, y)\n",
        "plt.plot([2.45, 2.45], [0, 3], \"k-\", linewidth\u003d2)\n",
        "plt.plot([2.45, 7.5], [1.75, 1.75], \"k--\", linewidth\u003d2)\n",
        "plt.plot([4.95, 4.95], [0, 1.75], \"k:\", linewidth\u003d2)\n",
        "plt.plot([4.85, 4.85], [1.75, 3], \"k:\", linewidth\u003d2)\n",
        "plt.text(1.40, 1.0, \"Depth\u003d0\", fontsize\u003d15)\n",
        "plt.text(3.2, 1.80, \"Depth\u003d1\", fontsize\u003d13)\n",
        "plt.text(4.05, 0.5, \"(Depth\u003d2)\", fontsize\u003d11)\n",
        "\n",
        "save_fig(\"decision_tree_decision_boundaries_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "# Predicting classes and class probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": "array([[0.        , 0.90740741, 0.09259259]])"
          },
          "metadata": {},
          "output_type": "execute_result",
          "execution_count": 7
        }
      ],
      "source": [
        "tree_clf.predict_proba([[5, 1.5]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": "array([1])"
          },
          "metadata": {},
          "output_type": "execute_result",
          "execution_count": 8
        }
      ],
      "source": [
        "tree_clf.predict([[5, 1.5]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "# Sensitivity to training set details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": "array([[4.8, 1.8]])"
          },
          "metadata": {},
          "output_type": "execute_result",
          "execution_count": 9
        }
      ],
      "source": [
        "X[(X[:, 1]\u003d\u003dX[:, 1][y\u003d\u003d1].max()) \u0026 (y\u003d\u003d1)] # widest Iris-Versicolor flower"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": "DecisionTreeClassifier(class_weight\u003dNone, criterion\u003d\u0027gini\u0027, max_depth\u003d2,\n            max_features\u003dNone, max_leaf_nodes\u003dNone,\n            min_impurity_decrease\u003d0.0, min_impurity_split\u003dNone,\n            min_samples_leaf\u003d1, min_samples_split\u003d2,\n            min_weight_fraction_leaf\u003d0.0, presort\u003dFalse, random_state\u003d40,\n            splitter\u003d\u0027best\u0027)"
          },
          "metadata": {},
          "output_type": "execute_result",
          "execution_count": 10
        }
      ],
      "source": [
        "not_widest_versicolor \u003d (X[:, 1]!\u003d1.8) | (y\u003d\u003d2)\n",
        "X_tweaked \u003d X[not_widest_versicolor]\n",
        "y_tweaked \u003d y[not_widest_versicolor]\n",
        "\n",
        "tree_clf_tweaked \u003d DecisionTreeClassifier(max_depth\u003d2, random_state\u003d40)\n",
        "tree_clf_tweaked.fit(X_tweaked, y_tweaked)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m\u003cipython-input-11-c15c495be198\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[1;34m\u001b[0m\n\u001b[1;32m----\u003e 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m\u003d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplot_decision_boundary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree_clf_tweaked\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_tweaked\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_tweaked\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlegend\u001b[0m\u001b[1;33m\u003d\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7.5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"k-\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[1;33m\u003d\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7.5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1.75\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.75\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"k--\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[1;33m\u003d\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Depth\u003d0\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[1;33m\u003d\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name \u0027plt\u0027 is not defined"
          ],
          "ename": "NameError",
          "evalue": "name \u0027plt\u0027 is not defined",
          "output_type": "error"
        }
      ],
      "source": [
        "plt.figure(figsize\u003d(8, 4))\n",
        "plot_decision_boundary(tree_clf_tweaked, X_tweaked, y_tweaked, legend\u003dFalse)\n",
        "plt.plot([0, 7.5], [0.8, 0.8], \"k-\", linewidth\u003d2)\n",
        "plt.plot([0, 7.5], [1.75, 1.75], \"k--\", linewidth\u003d2)\n",
        "plt.text(1.0, 0.9, \"Depth\u003d0\", fontsize\u003d15)\n",
        "plt.text(1.0, 1.80, \"Depth\u003d1\", fontsize\u003d13)\n",
        "\n",
        "save_fig(\"decision_tree_instability_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m\u003cipython-input-12-8f619e653a97\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdeep_tree_clf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mym\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----\u003e 9\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m\u003d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m121\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mplot_decision_boundary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep_tree_clf1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mym\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m\u003d\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miris\u001b[0m\u001b[1;33m\u003d\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name \u0027plt\u0027 is not defined"
          ],
          "ename": "NameError",
          "evalue": "name \u0027plt\u0027 is not defined",
          "output_type": "error"
        }
      ],
      "source": [
        "from sklearn.datasets import make_moons\n",
        "Xm, ym \u003d make_moons(n_samples\u003d100, noise\u003d0.25, random_state\u003d53)\n",
        "\n",
        "deep_tree_clf1 \u003d DecisionTreeClassifier(random_state\u003d42)\n",
        "deep_tree_clf2 \u003d DecisionTreeClassifier(min_samples_leaf\u003d4, random_state\u003d42)\n",
        "deep_tree_clf1.fit(Xm, ym)\n",
        "deep_tree_clf2.fit(Xm, ym)\n",
        "\n",
        "plt.figure(figsize\u003d(11, 4))\n",
        "plt.subplot(121)\n",
        "plot_decision_boundary(deep_tree_clf1, Xm, ym, axes\u003d[-1.5, 2.5, -1, 1.5], iris\u003dFalse)\n",
        "plt.title(\"No restrictions\", fontsize\u003d16)\n",
        "plt.subplot(122)\n",
        "plot_decision_boundary(deep_tree_clf2, Xm, ym, axes\u003d[-1.5, 2.5, -1, 1.5], iris\u003dFalse)\n",
        "plt.title(\"min_samples_leaf \u003d {}\".format(deep_tree_clf2.min_samples_leaf), fontsize\u003d14)\n",
        "\n",
        "save_fig(\"min_samples_leaf_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m\u003cipython-input-13-6d2b33d59986\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[1;34m\u001b[0m\n\u001b[1;32m----\u003e 1\u001b[1;33m \u001b[0mangle\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m180\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mrotation_matrix\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mangle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mangle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mangle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mangle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mXr\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrotation_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtree_clf_r\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m\u003d\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name \u0027np\u0027 is not defined"
          ],
          "ename": "NameError",
          "evalue": "name \u0027np\u0027 is not defined",
          "output_type": "error"
        }
      ],
      "source": [
        "angle \u003d np.pi / 180 * 20\n",
        "rotation_matrix \u003d np.array([[np.cos(angle), -np.sin(angle)], [np.sin(angle), np.cos(angle)]])\n",
        "Xr \u003d X.dot(rotation_matrix)\n",
        "\n",
        "tree_clf_r \u003d DecisionTreeClassifier(random_state\u003d42)\n",
        "tree_clf_r.fit(Xr, y)\n",
        "\n",
        "plt.figure(figsize\u003d(8, 3))\n",
        "plot_decision_boundary(tree_clf_r, Xr, y, axes\u003d[0.5, 7.5, -1.0, 1], iris\u003dFalse)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m\u003cipython-input-14-dc4f3c24cdf6\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[1;34m\u001b[0m\n\u001b[1;32m----\u003e 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mXs\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mys\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m\u003e\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mangle\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name \u0027np\u0027 is not defined"
          ],
          "ename": "NameError",
          "evalue": "name \u0027np\u0027 is not defined",
          "output_type": "error"
        }
      ],
      "source": [
        "np.random.seed(6)\n",
        "Xs \u003d np.random.rand(100, 2) - 0.5\n",
        "ys \u003d (Xs[:, 0] \u003e 0).astype(np.float32) * 2\n",
        "\n",
        "angle \u003d np.pi / 4\n",
        "rotation_matrix \u003d np.array([[np.cos(angle), -np.sin(angle)], [np.sin(angle), np.cos(angle)]])\n",
        "Xsr \u003d Xs.dot(rotation_matrix)\n",
        "\n",
        "tree_clf_s \u003d DecisionTreeClassifier(random_state\u003d42)\n",
        "tree_clf_s.fit(Xs, ys)\n",
        "tree_clf_sr \u003d DecisionTreeClassifier(random_state\u003d42)\n",
        "tree_clf_sr.fit(Xsr, ys)\n",
        "\n",
        "plt.figure(figsize\u003d(11, 4))\n",
        "plt.subplot(121)\n",
        "plot_decision_boundary(tree_clf_s, Xs, ys, axes\u003d[-0.7, 0.7, -0.7, 0.7], iris\u003dFalse)\n",
        "plt.subplot(122)\n",
        "plot_decision_boundary(tree_clf_sr, Xsr, ys, axes\u003d[-0.7, 0.7, -0.7, 0.7], iris\u003dFalse)\n",
        "\n",
        "save_fig(\"sensitivity_to_rotation_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "# Regression trees"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m\u003cipython-input-15-e6871cc4a239\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Quadratic training set + noise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----\u003e 2\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mm\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[1;36m4\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name \u0027np\u0027 is not defined"
          ],
          "ename": "NameError",
          "evalue": "name \u0027np\u0027 is not defined",
          "output_type": "error"
        }
      ],
      "source": [
        "# Quadratic training set + noise\n",
        "np.random.seed(42)\n",
        "m \u003d 200\n",
        "X \u003d np.random.rand(m, 1)\n",
        "y \u003d 4 * (X - 0.5) ** 2\n",
        "y \u003d y + np.random.randn(m, 1) / 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": "DecisionTreeRegressor(criterion\u003d\u0027mse\u0027, max_depth\u003d2, max_features\u003dNone,\n           max_leaf_nodes\u003dNone, min_impurity_decrease\u003d0.0,\n           min_impurity_split\u003dNone, min_samples_leaf\u003d1,\n           min_samples_split\u003d2, min_weight_fraction_leaf\u003d0.0,\n           presort\u003dFalse, random_state\u003d42, splitter\u003d\u0027best\u0027)"
          },
          "metadata": {},
          "output_type": "execute_result",
          "execution_count": 16
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "tree_reg \u003d DecisionTreeRegressor(max_depth\u003d2, random_state\u003d42)\n",
        "tree_reg.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m\u003cipython-input-17-407e35fd752a\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r.-\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[1;33m\u003d\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m\u003d\u001b[0m\u001b[1;34mr\"$\\hat{y}$\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---\u003e 18\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m\u003d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m121\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mplot_regression_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree_reg1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name \u0027plt\u0027 is not defined"
          ],
          "ename": "NameError",
          "evalue": "name \u0027plt\u0027 is not defined",
          "output_type": "error"
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "tree_reg1 \u003d DecisionTreeRegressor(random_state\u003d42, max_depth\u003d2)\n",
        "tree_reg2 \u003d DecisionTreeRegressor(random_state\u003d42, max_depth\u003d3)\n",
        "tree_reg1.fit(X, y)\n",
        "tree_reg2.fit(X, y)\n",
        "\n",
        "def plot_regression_predictions(tree_reg, X, y, axes\u003d[0, 1, -0.2, 1], ylabel\u003d\"$y$\"):\n",
        "    x1 \u003d np.linspace(axes[0], axes[1], 500).reshape(-1, 1)\n",
        "    y_pred \u003d tree_reg.predict(x1)\n",
        "    plt.axis(axes)\n",
        "    plt.xlabel(\"$x_1$\", fontsize\u003d18)\n",
        "    if ylabel:\n",
        "        plt.ylabel(ylabel, fontsize\u003d18, rotation\u003d0)\n",
        "    plt.plot(X, y, \"b.\")\n",
        "    plt.plot(x1, y_pred, \"r.-\", linewidth\u003d2, label\u003dr\"$\\hat{y}$\")\n",
        "\n",
        "plt.figure(figsize\u003d(11, 4))\n",
        "plt.subplot(121)\n",
        "plot_regression_predictions(tree_reg1, X, y)\n",
        "for split, style in ((0.1973, \"k-\"), (0.0917, \"k--\"), (0.7718, \"k--\")):\n",
        "    plt.plot([split, split], [-0.2, 1], style, linewidth\u003d2)\n",
        "plt.text(0.21, 0.65, \"Depth\u003d0\", fontsize\u003d15)\n",
        "plt.text(0.01, 0.2, \"Depth\u003d1\", fontsize\u003d13)\n",
        "plt.text(0.65, 0.8, \"Depth\u003d1\", fontsize\u003d13)\n",
        "plt.legend(loc\u003d\"upper center\", fontsize\u003d18)\n",
        "plt.title(\"max_depth\u003d2\", fontsize\u003d14)\n",
        "\n",
        "plt.subplot(122)\n",
        "plot_regression_predictions(tree_reg2, X, y, ylabel\u003dNone)\n",
        "for split, style in ((0.1973, \"k-\"), (0.0917, \"k--\"), (0.7718, \"k--\")):\n",
        "    plt.plot([split, split], [-0.2, 1], style, linewidth\u003d2)\n",
        "for split in (0.0458, 0.1298, 0.2873, 0.9040):\n",
        "    plt.plot([split, split], [-0.2, 1], \"k:\", linewidth\u003d1)\n",
        "plt.text(0.3, 0.5, \"Depth\u003d2\", fontsize\u003d13)\n",
        "plt.title(\"max_depth\u003d3\", fontsize\u003d14)\n",
        "\n",
        "save_fig(\"tree_regression_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m\u003cipython-input-18-127f134e6f02\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m export_graphviz(\n\u001b[0;32m      2\u001b[0m         \u001b[0mtree_reg1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----\u003e 3\u001b[1;33m         \u001b[0mout_file\u001b[0m\u001b[1;33m\u003d\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"regression_tree.dot\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mfeature_names\u001b[0m\u001b[1;33m\u003d\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"x1\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mrounded\u001b[0m\u001b[1;33m\u003d\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name \u0027image_path\u0027 is not defined"
          ],
          "ename": "NameError",
          "evalue": "name \u0027image_path\u0027 is not defined",
          "output_type": "error"
        }
      ],
      "source": [
        "export_graphviz(\n",
        "        tree_reg1,\n",
        "        out_file\u003dimage_path(\"regression_tree.dot\"),\n",
        "        feature_names\u003d[\"x1\"],\n",
        "        rounded\u003dTrue,\n",
        "        filled\u003dTrue\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m\u003cipython-input-19-cdbc85aa1ff7\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtree_reg2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----\u003e 6\u001b[1;33m \u001b[0mx1\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0my_pred1\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mtree_reg1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0my_pred2\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mtree_reg2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name \u0027np\u0027 is not defined"
          ],
          "ename": "NameError",
          "evalue": "name \u0027np\u0027 is not defined",
          "output_type": "error"
        }
      ],
      "source": [
        "tree_reg1 \u003d DecisionTreeRegressor(random_state\u003d42)\n",
        "tree_reg2 \u003d DecisionTreeRegressor(random_state\u003d42, min_samples_leaf\u003d10)\n",
        "tree_reg1.fit(X, y)\n",
        "tree_reg2.fit(X, y)\n",
        "\n",
        "x1 \u003d np.linspace(0, 1, 500).reshape(-1, 1)\n",
        "y_pred1 \u003d tree_reg1.predict(x1)\n",
        "y_pred2 \u003d tree_reg2.predict(x1)\n",
        "\n",
        "plt.figure(figsize\u003d(11, 4))\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.plot(X, y, \"b.\")\n",
        "plt.plot(x1, y_pred1, \"r.-\", linewidth\u003d2, label\u003dr\"$\\hat{y}$\")\n",
        "plt.axis([0, 1, -0.2, 1.1])\n",
        "plt.xlabel(\"$x_1$\", fontsize\u003d18)\n",
        "plt.ylabel(\"$y$\", fontsize\u003d18, rotation\u003d0)\n",
        "plt.legend(loc\u003d\"upper center\", fontsize\u003d18)\n",
        "plt.title(\"No restrictions\", fontsize\u003d14)\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.plot(X, y, \"b.\")\n",
        "plt.plot(x1, y_pred2, \"r.-\", linewidth\u003d2, label\u003dr\"$\\hat{y}$\")\n",
        "plt.axis([0, 1, -0.2, 1.1])\n",
        "plt.xlabel(\"$x_1$\", fontsize\u003d18)\n",
        "plt.title(\"min_samples_leaf\u003d{}\".format(tree_reg2.min_samples_leaf), fontsize\u003d14)\n",
        "\n",
        "save_fig(\"tree_regression_regularization_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "pycharm": {}
      },
      "source": [
        "# Exercise solutions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## 1. to 6."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "See appendix A."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "pycharm": {}
      },
      "source": [
        "## 7."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "_Exercise: train and fine-tune a Decision Tree for the moons dataset._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "a. Generate a moons dataset using `make_moons(n_samples\u003d10000, noise\u003d0.4)`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "Adding `random_state\u003d42` to make this notebook\u0027s output constant:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_moons\n",
        "\n",
        "X, y \u003d make_moons(n_samples\u003d10000, noise\u003d0.4, random_state\u003d42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "b. Split it into a training set and a test set using `train_test_split()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test \u003d train_test_split(X, y, test_size\u003d0.2, random_state\u003d42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "c. Use grid search with cross-validation (with the help of the `GridSearchCV` class) to find good hyperparameter values for a `DecisionTreeClassifier`. Hint: try various values for `max_leaf_nodes`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 294 candidates, totalling 882 fits\n"
          ],
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs\u003d-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs\u003d-1)]: Done 298 tasks      | elapsed:    2.1s\n",
            "[Parallel(n_jobs\u003d-1)]: Done 882 out of 882 | elapsed:    3.8s finished\n"
          ],
          "output_type": "stream"
        },
        {
          "data": {
            "text/plain": "GridSearchCV(cv\u003d3, error_score\u003d\u0027raise-deprecating\u0027,\n       estimator\u003dDecisionTreeClassifier(class_weight\u003dNone, criterion\u003d\u0027gini\u0027, max_depth\u003dNone,\n            max_features\u003dNone, max_leaf_nodes\u003dNone,\n            min_impurity_decrease\u003d0.0, min_impurity_split\u003dNone,\n            min_samples_leaf\u003d1, min_samples_split\u003d2,\n            min_weight_fraction_leaf\u003d0.0, presort\u003dFalse, random_state\u003d42,\n            splitter\u003d\u0027best\u0027),\n       fit_params\u003dNone, iid\u003d\u0027warn\u0027, n_jobs\u003d-1,\n       param_grid\u003d{\u0027max_leaf_nodes\u0027: [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99], \u0027min_samples_split\u0027: [2, 3, 4]},\n       pre_dispatch\u003d\u00272*n_jobs\u0027, refit\u003dTrue, return_train_score\u003d\u0027warn\u0027,\n       scoring\u003dNone, verbose\u003d1)"
          },
          "metadata": {},
          "output_type": "execute_result",
          "execution_count": 22
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "params \u003d {\u0027max_leaf_nodes\u0027: list(range(2, 100)), \u0027min_samples_split\u0027: [2, 3, 4]}\n",
        "grid_search_cv \u003d GridSearchCV(DecisionTreeClassifier(random_state\u003d42), params, n_jobs\u003d-1, verbose\u003d1, cv\u003d3)\n",
        "\n",
        "grid_search_cv.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": "DecisionTreeClassifier(class_weight\u003dNone, criterion\u003d\u0027gini\u0027, max_depth\u003dNone,\n            max_features\u003dNone, max_leaf_nodes\u003d17,\n            min_impurity_decrease\u003d0.0, min_impurity_split\u003dNone,\n            min_samples_leaf\u003d1, min_samples_split\u003d2,\n            min_weight_fraction_leaf\u003d0.0, presort\u003dFalse, random_state\u003d42,\n            splitter\u003d\u0027best\u0027)"
          },
          "metadata": {},
          "output_type": "execute_result",
          "execution_count": 23
        }
      ],
      "source": [
        "grid_search_cv.best_estimator_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "d. Train it on the full training set using these hyperparameters, and measure your model\u0027s performance on the test set. You should get roughly 85% to 87% accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "By default, `GridSearchCV` trains the best model found on the whole training set (you can change this by setting `refit\u003dFalse`), so we don\u0027t need to do it again. We can simply evaluate the model\u0027s accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": "0.8695"
          },
          "metadata": {},
          "output_type": "execute_result",
          "execution_count": 24
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred \u003d grid_search_cv.predict(X_test)\n",
        "accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## 8."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "_Exercise: Grow a forest._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "a. Continuing the previous exercise, generate 1,000 subsets of the training set, each containing 100 instances selected randomly. Hint: you can use Scikit-Learn\u0027s `ShuffleSplit` class for this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import ShuffleSplit\n",
        "\n",
        "n_trees \u003d 1000\n",
        "n_instances \u003d 100\n",
        "\n",
        "mini_sets \u003d []\n",
        "\n",
        "rs \u003d ShuffleSplit(n_splits\u003dn_trees, test_size\u003dlen(X_train) - n_instances, random_state\u003d42)\n",
        "for mini_train_index, mini_test_index in rs.split(X_train):\n",
        "    X_mini_train \u003d X_train[mini_train_index]\n",
        "    y_mini_train \u003d y_train[mini_train_index]\n",
        "    mini_sets.append((X_mini_train, y_mini_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "b. Train one Decision Tree on each subset, using the best hyperparameter values found above. Evaluate these 1,000 Decision Trees on the test set. Since they were trained on smaller sets, these Decision Trees will likely perform worse than the first Decision Tree, achieving only about 80% accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m\u003cipython-input-26-b22b6f20c219\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0maccuracy_scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---\u003e 13\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_scores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m: name \u0027np\u0027 is not defined"
          ],
          "ename": "NameError",
          "evalue": "name \u0027np\u0027 is not defined",
          "output_type": "error"
        }
      ],
      "source": [
        "from sklearn.base import clone\n",
        "\n",
        "forest \u003d [clone(grid_search_cv.best_estimator_) for _ in range(n_trees)]\n",
        "\n",
        "accuracy_scores \u003d []\n",
        "\n",
        "for tree, (X_mini_train, y_mini_train) in zip(forest, mini_sets):\n",
        "    tree.fit(X_mini_train, y_mini_train)\n",
        "    \n",
        "    y_pred \u003d tree.predict(X_test)\n",
        "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
        "\n",
        "np.mean(accuracy_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "c. Now comes the magic. For each test set instance, generate the predictions of the 1,000 Decision Trees, and keep only the most frequent prediction (you can use SciPy\u0027s `mode()` function for this). This gives you _majority-vote predictions_ over the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "Y_pred \u003d np.empty([n_trees, len(X_test)], dtype\u003dnp.uint8)\n",
        "\n",
        "for tree_index, tree in enumerate(forest):\n",
        "    Y_pred[tree_index] \u003d tree.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "from scipy.stats import mode\n",
        "\n",
        "y_pred_majority_votes, n_votes \u003d mode(Y_pred, axis\u003d0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "d. Evaluate these predictions on the test set: you should obtain a slightly higher accuracy than your first model (about 0.5 to 1.5% higher). Congratulations, you have trained a Random Forest classifier!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.872"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy_score(y_test, y_pred_majority_votes.reshape([-1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "nav_menu": {
      "height": "309px",
      "width": "468px"
    },
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}